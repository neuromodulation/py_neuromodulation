{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# First Demo\n\nThis Demo will showcase the feature estimation and\nexemplar analysis using simulated data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimport py_neuromodulation as nm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Simulation\nWe will now generate some exemplar data with 10 second duration for 6 channels with a sample rate of 1 kHz.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_random_walk(NUM_CHANNELS, TIME_DATA_SAMPLES):\n    # from https://towardsdatascience.com/random-walks-with-python-8420981bc4bc\n    dims = NUM_CHANNELS\n    step_n = TIME_DATA_SAMPLES - 1\n    step_set = [-1, 0, 1]\n    origin = (np.random.random([1, dims]) - 0.5) * 1  # Simulate steps in 1D\n    step_shape = (step_n, dims)\n    steps = np.random.choice(a=step_set, size=step_shape)\n    path = np.concatenate([origin, steps]).cumsum(0)\n    return path.T\n\n\nNUM_CHANNELS = 6\nsfreq = 1000\nTIME_DATA_SAMPLES = 10 * sfreq\ndata = generate_random_walk(NUM_CHANNELS, TIME_DATA_SAMPLES)\ntime = np.arange(0, TIME_DATA_SAMPLES / sfreq, 1 / sfreq)\n\nplt.figure(figsize=(8, 4), dpi=100)\nfor ch_idx in range(data.shape[0]):\n    plt.plot(time, data[ch_idx, :])\nplt.xlabel(\"Time [s]\")\nplt.ylabel(\"Amplitude\")\nplt.title(\"Example random walk data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let\u2019s define the necessary setup files we will be using for data\npreprocessing and feature estimation. Py_neuromodualtion is based on two\nparametrization files: the *channels.tsv* and the *default_settings.json*.\n\n### nm_channels\n\nThe *nm_channel* dataframe. This dataframe contains the columns\n\n+-----------------------------------+-----------------------------------+\n| Column name                       | Description                       |\n+===================================+===================================+\n| **name**                          | name of the channel               |\n+-----------------------------------+-----------------------------------+\n| **rereference**                   | different channel name for        |\n|                                   | bipolar re-referencing, or        |\n|                                   | average for common average        |\n|                                   | re-referencing                    |\n+-----------------------------------+-----------------------------------+\n| **used**                          | 0 or 1, channel selection         |\n+-----------------------------------+-----------------------------------+\n| **target**                        | 0 or 1, for some decoding         |\n|                                   | applications we can define target |\n|                                   | channels, e.g.\u00a0EMG channels       |\n+-----------------------------------+-----------------------------------+\n| **type**                          | channel type according to the     |\n|                                   | `mne-python`_ toolbox             |\n|                                   |                                   |\n|                                   |                                   |\n|                                   |                                   |\n|                                   |                                   |\n|                                   | e.g.\u00a0ecog, eeg, ecg, emg, dbs,    |\n|                                   | seeg etc.                         |\n+-----------------------------------+-----------------------------------+\n| **status**                        | good or bad, used for channel     |\n|                                   | quality indication                |\n+-----------------------------------+-----------------------------------+\n| **new_name**                      | this keyword can be specified to  |\n|                                   | indicate for example the used     |\n|                                   | rereferncing scheme               |\n+-----------------------------------+-----------------------------------+\n\n\nThe :class:`~nm_stream_abc` can either be created as a *.tsv* text file, or as a pandas\nDataFrame. There are some helper functions that let you create the\nnm_channels without much effort:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nm_channels = nm.utils.get_default_channels_from_data(data, car_rereferencing=True)\n\nnm_channels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this function default channel names and a common average re-referencing scheme is specified.\nAlternatively the *define_nmchannels.set_channels* function can be used to pass each column values.\n\n## nm_settings\nNext, we will initialize the nm_settings dictionary and use the default settings, reset them, and enable a subset of features:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "settings = nm.NMSettings.get_fast_compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The setting itself is a .json file which contains the parametrization for preprocessing, feature estimation, postprocessing and\ndefinition with which sampling rate features are being calculated.\nIn this example `sampling_rate_features_hz` is specified to be 10 Hz, so every 100ms a new set of features is calculated.\n\nFor many features the `segment_length_features_ms` specifies the time dimension of the raw signal being used for feature calculation. Here it is specified to be 1000 ms.\n\nWe will now enable the features:\n\n* fft\n* bursts\n* sharpwave\n\nand stay with the default preprcessing methods:\n\n* notch_filter\n* re_referencing\n\nand use *z-score* postprocessing normalization.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "settings.features.fooof = True\nsettings.features.fft = True\nsettings.features.bursts = True\nsettings.features.sharpwave_analysis = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are now ready to go to instantiate the *Stream* and call the *run* method for feature estimation:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stream = nm.Stream(\n    settings=settings,\n    channels=nm_channels,\n    verbose=True,\n    sfreq=sfreq,\n    line_noise=50,\n)\n\nfeatures = stream.run(data, save_csv=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Analysis\n\nThere is a lot of output, which we could omit by verbose being False, but let's have a look what was being computed.\nWe will therefore use the :class:`~nm_analysis` class to showcase some functions. For multi-run -or subject analysis we will pass here the feature_file \"sub\" as default directory:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analyzer = nm.FeatureReader(\n    feature_dir=stream.out_dir, feature_file=stream.experiment_name\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have a look at the resulting \"feature_arr\" DataFrame:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analyzer.feature_arr.iloc[:10, :7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seems like a lot of features were calculated. The `time` column tells us about each row time index.\nFor the 6 specified channels, it is each 31 features.\nWe can now use some in-built plotting functions for visualization.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Due to the nature of simulated data, some of the features have constant values, which are not displayed through the image normalization.</p></div>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analyzer.plot_all_features(ch_used=\"ch1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nm.analysis.plot_corr_matrix(\n    figsize=(25, 25),\n    show_plot=True,\n    feature=analyzer.feature_arr,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The upper correlation matrix shows the correlation of every feature of every channel to every other.\nThis notebook demonstrated a first demo how features can quickly be generated. For further feature modalities and decoding applications check out the next notebooks.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}