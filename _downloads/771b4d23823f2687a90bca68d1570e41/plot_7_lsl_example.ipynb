{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Lab Streaming Layer (LSL) Example\n\nThis toolbox implements the lsl ecosystem which can be utilized for offline use cases as well as live streamings\nIn this example the data introduced in the first demo is being analyzed\nin a similar manner, This time however integrating an lsl stream.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\nimport py_neuromodulation as nm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s get the example data from the provided BIDS dataset and create the channels DataFrame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n    (\n        RUN_NAME,\n        PATH_RUN,\n        PATH_BIDS,\n        PATH_OUT,\n        datatype,\n    ) = nm.io.get_paths_example_data()\n\n    (\n        raw,\n        data,\n        sfreq,\n        line_noise,\n        coord_list,\n        coord_names,\n    ) = nm.io.read_BIDS_data(PATH_RUN=PATH_RUN)\n\n    channels = nm.utils.set_channels(\n        ch_names=raw.ch_names,\n        ch_types=raw.get_channel_types(),\n        reference=\"default\",\n        bads=raw.info[\"bads\"],\n        new_names=\"default\",\n        used_types=(\"ecog\", \"dbs\", \"seeg\"),\n        target_keywords=[\"MOV_RIGHT\"],\n    )\n\n    # %%\n    # Playing the Data\n    # ----------------\n    #\n    # Now we need our data to be represeted in the LSL stream.\n    # For this example an mne_lsl.Player is utilized, which is playing our earlier\n    # recorded data. However, you could make use of any LSL source (live or\n    # offline).\n    # If you want to bind your own data source, make sure to specify the\n    # necessary parameters (data type, type, name) accordingly.\n    # If you are unsure about the parameters of your data source you can\n    # always search for available lsl streams.\n    #\n\n    settings = nm.NMSettings.get_fast_compute()\n\n    player = nm.stream.LSLOfflinePlayer(raw=raw, stream_name=\"example_stream\")\n\n    player.start_player(chunk_size=30, n_repeat=1)\n    import time\n\n    time.sleep(5)\n    # %%\n    # Creating the LSLStream object\n    # -----------------------------\n    #\n    # Next let\u2019s create a Stream analog to the First Demo\u2019s example However as\n    # we run the stream, we will set the *lsl-stream* value to True and pass\n    # the stream name we earlier declared when initializing the player object.\n\n    settings.features.welch = False\n    settings.features.fft = True\n    settings.features.bursts = False\n    settings.features.sharpwave_analysis = False\n    settings.features.coherence = False\n\n    # %%\n    stream = nm.Stream(\n        sfreq=sfreq,\n        channels=channels,\n        settings=settings,\n        coord_list=coord_list,\n        verbose=True,\n        line_noise=line_noise,\n    )\n    # %%\n    # We then simply have to set the `stream_lsl` parameter to be `True` and specify the `stream_lsl_name`.\n    # Schedule \"stop\" insertion in 5 seconds\n    features = stream.run(\n        is_stream_lsl=True,\n        stream_lsl_name=\"example_stream\",\n        out_dir=PATH_OUT,\n        experiment_name=RUN_NAME,\n    )\n\n    player.stop_player()\n\n    # %%\n    # We can then look at the computed features and check if the streamed data was processed correctly.\n    # This can be verified by the time label:\n\n    plt.plot(features.time, features.MOV_RIGHT)\n\n    ######################################################################\n    # Feature Analysis of Movement\n    # ----------------------------\n    # We can now check the movement averaged features of an ECoG channel.\n    # Note that the path was here adapted to be documentation build compliant.\n\n    feature_reader = nm.analysis.FeatureReader(\n        feature_dir=PATH_OUT, feature_file=RUN_NAME\n    )\n    feature_reader.label_name = \"MOV_RIGHT\"\n    feature_reader.label = feature_reader.feature_arr[\"MOV_RIGHT\"]\n\n    feature_reader.plot_target_averaged_channel(\n        ch=\"ECOG_RIGHT_0\",\n        list_feature_keywords=None,\n        epoch_len=4,\n        threshold=0.5,\n        ytick_labelsize=7,\n        figsize_x=12,\n        figsize_y=12,\n    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}